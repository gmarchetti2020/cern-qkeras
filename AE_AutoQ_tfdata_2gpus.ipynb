{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e77927",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --user qkeras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1b6590",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f9c9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model,model_from_json\n",
    "from tensorflow.keras.layers import Input, InputLayer, Dense, Lambda, BatchNormalization, Activation, Concatenate, Dropout, Layer\n",
    "from tensorflow.keras.layers import ReLU, LeakyReLU\n",
    "from tensorflow.keras import backend as K\n",
    "from qkeras import QDense, QActivation\n",
    "import math\n",
    "\n",
    "from datetime import datetime\n",
    "from tensorboard import program\n",
    "import os\n",
    "import pathlib\n",
    "#import tensorflow_model_optimization as tfmot\n",
    "#tsk = tfmot.sparsity.keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "#from functions import preprocess_anomaly_data, custom_loss_negative, custom_loss_training\n",
    "from functions_dist import preprocess_anomaly_data, custom_loss_negative, custom_loss_training, save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.compat.v1.enable_eager_execution()\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fff9085",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices()\n",
    "for d in physical_devices:\n",
    "  print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44f49f3",
   "metadata": {},
   "source": [
    "# Computation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ea621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024 \n",
    "AUTOTUNE=tf.data.AUTOTUNE\n",
    "EPOCHS = 25\n",
    "NUM_EVALS=25\n",
    "#NUM_TRAIN_EXAMPLES=trainds.cardinality().numpy()\n",
    "NUM_SAMPLES=3000000\n",
    "STEPS_PER_EPOCH=NUM_SAMPLES//BATCH_SIZE\n",
    "#STEPS_PER_EPOCH=NUM_SAMPLES//(BATCH_SIZE*NUM_EVALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b004e7b4",
   "metadata": {},
   "source": [
    "# Build datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb81c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('Delphes_dataset_HALF.h5', 'r')\n",
    "#X_train_flatten = np.array(file['X_train_flatten'])\n",
    "X_test_flatten = np.array(file['X_test_flatten'])\n",
    "#X_val_flatten = np.array(file['X_val_flatten'])\n",
    "\n",
    "#X_train_scaled = np.array(file['X_train_scaled'])\n",
    "#X_test_scaled = np.array(file['X_test_scaled'])\n",
    "#X_val_scaled = np.array(file['X_val_scaled'])\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f57c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a401224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file='Delphes_dataset_HALF.h5'\n",
    "X_train_flatten_ds=tfio.IODataset.from_hdf5(file, '/X_train_flatten')\n",
    "#X_test_flatten_ds=tfio.IODataset.from_hdf5(file,'/X_test_flatten')\n",
    "X_val_flatten_ds=tfio.IODataset.from_hdf5(file, '/X_val_flatten')\n",
    "\n",
    "X_train_scaled_ds=tfio.IODataset.from_hdf5(file, '/X_train_scaled')\n",
    "X_val_scaled_ds=tfio.IODataset.from_hdf5(file,'/X_val_scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27edbe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_flatten_ds=tf.data.Dataset.from_tensor_slices(X_train_flatten).batch(BATCH_SIZE, drop_remainder=True).prefetch(AUTOTUNE)\n",
    "#X_test_flatten_ds=tf.data.Dataset.from_tensor_slices(X_test_flatten)\n",
    "#X_val_flatten_ds=tf.data.Dataset.from_tensor_slices(X_val_flatten)\n",
    "\n",
    "#X_train_scaled_ds=tf.data.Dataset.from_tensor_slices(X_train_scaled).batch(BATCH_SIZE, drop_remainder=True).prefetch(AUTOTUNE)\n",
    "#X_val_scaled_ds=tf.data.Dataset.from_tensor_slices(X_val_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111ea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainds=tf.data.Dataset.zip((X_train_flatten_ds, X_train_scaled_ds)).take(NUM_SAMPLES)\n",
    "trainds=trainds.shuffle(10*BATCH_SIZE).repeat(EPOCHS).batch(BATCH_SIZE, drop_remainder=True).prefetch(AUTOTUNE)\n",
    "#trainds=trainds.shuffle(BATCH_SIZE*10)\n",
    "#trainds=trainds.batch(BATCH_SIZE, drop_remainder=True)\n",
    "#trainds=trainds.prefetch(AUTOTUNE)\n",
    "valds=tf.data.Dataset.zip((X_val_flatten_ds, X_val_scaled_ds)).take(NUM_SAMPLES)\n",
    "valds=valds.repeat(EPOCHS).batch(BATCH_SIZE, drop_remainder=True).prefetch(AUTOTUNE)\n",
    "#valds=valds.shuffle(BATCH_SIZE*10).batch(BATCH_SIZE,drop_remainder=True).prefetch(AUTOTUNE)\n",
    "#X_test_flatten_ds=X_test_flatten_ds.shuffle(BATCH_SIZE*10).batch(BATCH_SIZE,drop_remainder=True).prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610cd345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(trainds.as_numpy_iterator())[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6603370b",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe0cb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 3\n",
    "input_shape = 56\n",
    "#strategy=tf.distribute.MirroredStrategy()\n",
    "\n",
    "#with strategy.scope():\n",
    "#encoder\n",
    "inputArray = Input(shape=(input_shape,))\n",
    "x = Activation('linear', name='block_1_act')(inputArray)\n",
    " #   else QActivation(f'quantized_bits(16,6,1)')(inputArray)\n",
    "x = BatchNormalization(name='bn_1')(x)\n",
    "x = Dense(32, kernel_initializer=tf.keras.initializers.HeUniform(),use_bias=False, name='block_2_dense')(x)\n",
    "x = BatchNormalization(name='bn_2')(x)\n",
    "x = Activation('relu', name='block_2_act')(x)\n",
    "x = Dense(16, kernel_initializer=tf.keras.initializers.HeUniform(),use_bias=False, name='block_3_dense')(x)\n",
    "x = BatchNormalization(name='bn_3')(x)\n",
    "x = Activation('relu', name='block_3_act')(x)\n",
    "encoder = Dense(latent_dim, kernel_initializer=tf.keras.initializers.HeUniform(),name='output_encoder')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "\n",
    "#decoder\n",
    "x = Dense(16, kernel_initializer=tf.keras.initializers.HeUniform(),use_bias=False, name='block_4_dense')(encoder)\n",
    "x = BatchNormalization(name='bn_4')(x)\n",
    "x = Activation('relu', name='block_4_act')(x)\n",
    "x = Dense(32, kernel_initializer=tf.keras.initializers.HeUniform(),use_bias=False, name='block_5_dense')(x)\n",
    "x = BatchNormalization(name='bn_5')(x)\n",
    "x = Activation('relu', name='block_5_act')(x)\n",
    "x = Dense(input_shape, kernel_initializer=tf.keras.initializers.HeUniform(), name='output_dense')(x)\n",
    "decoder = Activation('linear', name='output_act')(x)\n",
    "\n",
    "#create autoencoder\n",
    "autoencoder = Model(inputs = inputArray, outputs=decoder)\n",
    "autoencoder.compile(optimizer=keras.optimizers.Adam(), loss=custom_loss_training, \n",
    "                    #run_eagerly=True\n",
    "                   ) # just to make sure it runs in eager\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60979027",
   "metadata": {},
   "source": [
    "## Train without quantization\n",
    "This is just to understnd the timings involved and test the process so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b079ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "odir='output'\n",
    "callbacks=[]\n",
    "#if pruning=='pruned':\n",
    " #   callbacks.append(tfmot.sparsity.keras.UpdatePruningStep())\n",
    "callbacks.append(ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, verbose=1, mode='auto', min_delta=0.0001, cooldown=2, min_lr=1E-6))\n",
    "#callbacks.append(TerminateOnNaN())\n",
    "#callbacks.append(tf.keras.callbacks.ModelCheckpoint(filepath='{}/AUTOQKERAS_best.h5'.format(odir),monitor=\"val_loss\",verbose=1,save_best_only=True))\n",
    "#callbacks.append(tf.keras.callbacks.ModelCheckpoint(filepath='{}/AUTOQKERAS_best_weights.h5'.format(odir),monitor=\"val_loss\",verbose=0,save_weights_only=True))\n",
    "callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='val_loss',verbose=1, patience=8, restore_best_weights=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b823498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "history=autoencoder.fit(x=trainds, \n",
    "           validation_data=valds, \n",
    "           #batch_size=BATCH_SIZE,\n",
    "           epochs=EPOCHS,\n",
    "           #epochs=NUM_EVALS,\n",
    "           steps_per_epoch=STEPS_PER_EPOCH,\n",
    "           #validation_steps=NUM_EVALS,\n",
    "           callbacks=callbacks,\n",
    "                       verbose=1)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3812f84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('{}/AUTOQKERAS_best.h5'.format(odir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a34ce3",
   "metadata": {},
   "source": [
    "### Load signal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c334e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "ato4l = h5py.File('Ato4l_lepFilter_13TeV.h5', 'r')\n",
    "ato4l = ato4l['Particles'][:]\n",
    "ato4l = ato4l[:,:,:-1]\n",
    "\n",
    "import joblib\n",
    "pT_scaler = joblib.load('pt_scaled_VAE_new.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc40400",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaled_ato4l, test_notscaled_ato4l = preprocess_anomaly_data(pT_scaler, ato4l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5765e15",
   "metadata": {},
   "source": [
    "### Set objective and  compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db434994",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsm_data = test_notscaled_ato4l #input - data without any preprocessing\n",
    "#obj = roc_objective(autoencoder, X_test_flatten[:1000], bsm_data)\n",
    "#with strategy.scope():\n",
    "#    autoencoder.compile(optimizer=keras.optimizers.Adam(), loss=custom_loss_training, run_eagerly=True) # just to make sure it runs in eager\n",
    "#autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775032c3",
   "metadata": {},
   "source": [
    "### Override AutoQKeras classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Custom_AutoQKeras_dist import *\n",
    "#from Custom_AutoQKeras import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730582aa",
   "metadata": {},
   "source": [
    "### Set AutoQKeras parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab2a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras import *\n",
    "from qkeras.utils import model_quantize\n",
    "from qkeras.qtools import run_qtools\n",
    "from qkeras.qtools import settings as qtools_settings\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61cbc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_internal = \"fp32\"\n",
    "reference_accumulator = \"fp32\"\n",
    "\n",
    "q = run_qtools.QTools(\n",
    "  autoencoder,\n",
    "  # energy calculation using a given process\n",
    "  # \"horowitz\" refers to 45nm process published at\n",
    "  # M. Horowitz, \"1.1 Computing's energy problem (and what we can do about\n",
    "  # it), \"2014 IEEE International Solid-State Circuits Conference Digest of\n",
    "  # Technical Papers (ISSCC), San Francisco, CA, 2014, pp. 10-14, \n",
    "  # doi: 10.1109/ISSCC.2014.6757323.\n",
    "  process=\"horowitz\",\n",
    "  # quantizers for model input\n",
    "  source_quantizers=[quantized_bits(16, 6, 1)],\n",
    "  is_inference=False,\n",
    "  # absolute path (including filename) of the model weights\n",
    "  # in the future, we will attempt to optimize the power model\n",
    "  # by using weight information, although it can be used to further\n",
    "  # optimize QBatchNormalization.\n",
    "  weights_path=None,\n",
    "  # keras_quantizer to quantize weight/bias in un-quantized keras layers\n",
    "  keras_quantizer=reference_internal,\n",
    "  # keras_quantizer to quantize MAC in un-quantized keras layers\n",
    "  keras_accumulator=reference_accumulator,\n",
    "  # whether calculate baseline energy\n",
    "  for_reference=True)\n",
    "  \n",
    "# caculate energy of the derived data type map.\n",
    "energy_dict = q.pe(\n",
    "    # whether to store parameters in dram, sram, or fixed\n",
    "    weights_on_memory=\"sram\",\n",
    "    # store activations in dram or sram\n",
    "    activations_on_memory=\"sram\",\n",
    "    # minimum sram size in number of bits. Let's assume a 16MB SRAM.\n",
    "    min_sram_size=8*16*1024*1024,\n",
    "    rd_wr_on_io=False)\n",
    "\n",
    "# get stats of energy distribution in each layer\n",
    "energy_profile = q.extract_energy_profile(\n",
    "    qtools_settings.cfg.include_energy, energy_dict)\n",
    "# extract sum of energy of each layer according to the rule specified in\n",
    "# qtools_settings.cfg.include_energy\n",
    "total_energy = q.extract_energy_sum(\n",
    "    qtools_settings.cfg.include_energy, energy_dict)\n",
    "\n",
    "pprint.pprint(energy_profile)\n",
    "print()\n",
    "print(\"Total energy: {:.2f} uJ\".format(total_energy / 1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65813129",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = {\n",
    "        \"kernel\": {\n",
    "                \"quantized_bits(2,1,1,alpha=1.0)\": 2,\n",
    "                \"quantized_bits(4,2,1,alpha=1.0)\": 4,\n",
    "                \"quantized_bits(6,2,1,alpha=1.0)\": 6,\n",
    "                \"quantized_bits(8,3,1,alpha=1.0)\": 8,\n",
    "                \"quantized_bits(10,3,1,alpha=1.0)\": 10,\n",
    "                \"quantized_bits(12,4,1,alpha=1.0)\": 12,\n",
    "                \"quantized_bits(14,4,1,alpha=1.0)\": 14,\n",
    "                \"quantized_bits(16,6,1,alpha=1.0)\": 16\n",
    "        },\n",
    "        \"bias\": {\n",
    "                \"quantized_bits(2,1,1)\": 2,\n",
    "                \"quantized_bits(4,2,1)\": 4,\n",
    "                \"quantized_bits(6,2,1)\": 6,\n",
    "                \"quantized_bits(8,3,1)\": 8\n",
    "        },\n",
    "        \"activation\": {\n",
    "                \"quantized_relu(2,1)\": 2,\n",
    "                \"quantized_relu(3,1)\": 3,\n",
    "                \"quantized_relu(4,2)\": 4,\n",
    "                \"quantized_relu(6,2)\": 6,\n",
    "                \"quantized_relu(8,3)\": 8,\n",
    "                \"quantized_relu(10,3)\": 10,\n",
    "                \"quantized_relu(12,4)\": 12,\n",
    "                \"quantized_relu(14,4)\": 14,\n",
    "                \"quantized_relu(16,6)\": 16\n",
    "        },\n",
    "        \"linear\": {\n",
    "                \"quantized_bits(16,6)\": 16\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bc6ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = {\n",
    "    \"Dense\": [16, 8, 16],\n",
    "    \"Activation\": [16]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab9176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal = {\n",
    "    \"type\": \"energy\",\n",
    "    \"params\": {\n",
    "        \"delta_p\": 8.0,\n",
    "        \"delta_n\": 8.0,\n",
    "        \"rate\": 4.0, # a try\n",
    "        \"stress\": 0.6, # a try\n",
    "        \"process\": \"horowitz\",\n",
    "        \"parameters_on_memory\": [\"sram\", \"sram\"],\n",
    "        \"activations_on_memory\": [\"sram\", \"sram\"],\n",
    "        \"rd_wr_on_io\": [False, False],\n",
    "        \"min_sram_size\": [0, 0],\n",
    "        \"source_quantizers\": [\"fp16\"],\n",
    "        \"reference_internal\": \"fp16\",\n",
    "        \"reference_accumulator\": \"fp16\"\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b386d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "odir='autoqkeras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47431c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = {\n",
    "    \"output_dir\": \"{}/\".format(odir),\n",
    "    \"goal\": goal,\n",
    "    \"quantization_config\": quantization_config,\n",
    "    \"learning_rate_optimizer\": False,\n",
    "    \"transfer_weights\": False,\n",
    "    \"mode\": \"bayesian\", \n",
    "    #\"max_epochs\": 25, #changed for hyperband\n",
    "    \"score_metric\": \"val_custom_score\", # must have a metric for keras tuner to save\n",
    "    \"seed\": 42,\n",
    "    \"limit\": limit,\n",
    "    \"tune_filters\": \"layer\",\n",
    "    \"tune_filters_exceptions\": \"^output.*\",\n",
    "    \"layer_indexes\": [1,3,5,6,8,9,10,12,13,15,16,17],\n",
    "    \"max_trials\": 130,\n",
    "    #\"distribution_strategy\":strategy, #changed uncomment to enable multiple GPUS\n",
    "    \"blocks\": [\n",
    "          \"block_1_.*$\",\n",
    "          \"block_2_.*$\",\n",
    "          \"block_3_.*$\",\n",
    "          \"output_encoder$\",\n",
    "          \"block_4_.*$\",\n",
    "          \"block_5_.*$\",\n",
    "          \"output_dense$\",\n",
    "          \"output_act$\",],\n",
    "    \"schedule_block\": \"cost\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde7d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"quantizing layers:\", [autoencoder.layers[i].name for i in run_config[\"layer_indexes\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d09024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "outputdir='output'\n",
    "callbacks=[]\n",
    "#if pruning=='pruned':\n",
    " #   callbacks.append(tfmot.sparsity.keras.UpdatePruningStep())\n",
    "callbacks.append(ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, verbose=1, mode='auto', min_delta=0.0001, cooldown=2, min_lr=1E-6))\n",
    "#callbacks.append(TerminateOnNaN())\n",
    "#callbacks.append(tf.keras.callbacks.ModelCheckpoint(filepath='{}/AUTOQKERAS_best'.format(outputdir),monitor=\"val_loss\",verbose=1,save_best_only=True))\n",
    "#callbacks.append(tf.keras.callbacks.ModelCheckpoint(filepath='{}/AUTOQKERAS_best_weights.h5'.format(odir),monitor=\"val_loss\",verbose=0,save_weights_only=True))\n",
    "callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='val_loss',verbose=1, patience=8, restore_best_weights=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf67fa59",
   "metadata": {},
   "source": [
    "### Run search with AutoQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffc7c5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoqk = Custom_AutoQKerasScheduler(autoencoder,\n",
    "                                    metrics=[custom_loss_negative],\n",
    "                                    X_test = X_test_flatten[:NUM_SAMPLES],\n",
    "                                    bsm_data = bsm_data,\n",
    "                                    custom_objects={},\n",
    "                                    debug=False,\n",
    "                                    **run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb1d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "autoqk.fit(x=trainds, \n",
    "           validation_data=valds, \n",
    "           #batch_size=BATCH_SIZE,\n",
    "           epochs=EPOCHS,\n",
    "           #epochs=NUM_EVALS,\n",
    "           steps_per_epoch=STEPS_PER_EPOCH,\n",
    "           callbacks=callbacks,\n",
    "          verbose=1)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa14033",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel = autoqk.get_best_model()\n",
    "qmodel.summary()\n",
    "save_model('best_pretrain_objective_roc', qmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59fb11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
